{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "92cd942f-fd44-4922-8ef6-7f9697c59c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from collections import OrderedDict\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torchinfo import summary\n",
    "import pandas as pd\n",
    "from torchvision import datasets\n",
    "import os\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm.notebook import tqdm_notebook\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from torchvision import models, transforms, utils\n",
    "import os\n",
    "import torchvision\n",
    "from zipfile import ZipFile\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df2ffb8c-6cd3-4d7f-8aa3-a2e000d0a0f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"mnist_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f1a588-c485-43cf-aee5-c519cb9af4d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df[:,:-1]\n",
    "y = df[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e3b32b-ea10-422e-a702-f25a70955cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(x,y,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c989121a-06f1-41b3-bbef-6d10c352ad0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class class_Dataset(Dataset):\n",
    "    def __init__(self, features, labels, transform=None):\n",
    "        self.features = features\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        feature = self.features[idx]\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        # Reshape the feature into the original image shape (1, 28, 28) for MNIST\n",
    "        feature = feature.view(1, 48, 48)\n",
    "        \n",
    "        if self.transform:\n",
    "            feature = self.transform(feature)\n",
    "        \n",
    "        return feature, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e045734f-e40e-48c4-afd0-1c09af8d661a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define transformations for the images (e.g., resizing, normalization)\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),  # Convert images to PyTorch tensors\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])  # Normalize images\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3b2a73-252f-42ec-ab00-c7dced806cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of the custom dataset\n",
    "train_dataset = class_Dataset(X_train, y_train,transform=transform)\n",
    "test_dataset = class_Dataset(X_test, y_test,transform=transform)\n",
    "# Create a DataLoader\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2092f5a7-24ea-47a8-aadb-500d2387eda1",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37670e3a-b054-407e-8e9c-457c39a69196",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Length of training dataloader: {len(train_loader)} batches of {BATCH_SIZE}\")\n",
    "print(f\"Length of testing dataloader: {len(test_loader)} batches of {BATCH_SIZE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "071245ce-0b82-4ce6-8991-65d9950b3d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features, train_labels = next(iter(train_loader))\n",
    "print(f\"Feature batch shape: {train_features.size()}\")\n",
    "print(f\"Labels batch shape: {train_labels.size()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "090e21fc-ef6f-4351-9228-f81bdec17d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features, test_labels = next(iter(test_loader))\n",
    "print(f\"Feature batch shape: {test_features.size()}\")\n",
    "print(f\"Labels batch shape: {test_labels.size()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b07d94-8f42-4a25-b931-149ef3562795",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Function to unnormalize and show an image\n",
    "def imshow(img):\n",
    "    img = (img *0.5) + 0.5  # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# Get a batch of images and labels\n",
    "dataiter = iter(train_dataloader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "# Show images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "\n",
    "# Print labels\n",
    "print(' '.join(f'{train_data.classes[labels[j]]}' for j in range(len(labels))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c712c9e-7e1b-41b6-8432-0e4ea109db18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup device agnostic code\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b301e35-609c-48a3-acba-51954ada11ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenseLayer2(nn.Module):\n",
    "    def __init__(self, in_channels, growth_rate):\n",
    "        super().__init__()\n",
    "        self.bn = nn.BatchNorm2d(in_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv = nn.Conv2d(in_channels, growth_rate, kernel_size=3, padding=1, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv(self.relu(self.bn(x)))\n",
    "        out = torch.cat([x, out], 1)\n",
    "        return out\n",
    "\n",
    "class DenseBlock1(nn.Module):\n",
    "    def __init__(self, in_channels, growth_rate, n_layers):\n",
    "        super().__init__()\n",
    "        self.layer_num = n_layers\n",
    "        self.deep_nn = nn.ModuleList([DenseLayer2(in_channels+i*growth_rate,growth_rate) for i in range(n_layers)])\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        for i, l in enumerate(self.deep_nn):\n",
    "            x = self.deep_nn[i](x)\n",
    "        return x\n",
    "\n",
    "class TransitionLayer1(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.bn = nn.BatchNorm2d(in_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1, bias=False)\n",
    "        self.pool = nn.AvgPool2d(2, stride=2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv(self.relu(self.bn(x)))\n",
    "        out = self.pool(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a37b4cfb-411a-4fb1-81ef-8ad46084d1d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(OrderedDict([\n",
    "    ('Conv1',nn.Conv2d(3,32,kernel_size=7,padding=3,stride=2)),\n",
    "    ('ReLU1',nn.ReLU()),\n",
    "    ('MaxPool1',nn.MaxPool2d(kernel_size=3, stride=2, padding=1)),\n",
    "    ('DenseBlock1',DenseBlock1(32,16,4)),\n",
    "    ('TransitionLayer1',TransitionLayer1(96,48)),\n",
    "    ('DenseBlock2',DenseBlock1(48,16,8)),\n",
    "    ('TransitionLayer2',TransitionLayer1(176,88)),\n",
    "    ('DenseBlock3',DenseBlock1(88,16,16)),\n",
    "    ('TransitionLayer3',TransitionLayer1(344,172)),\n",
    "    ('DenseBlock4',DenseBlock1(172,16,8)),\n",
    "    ('Batchnorm1',nn.BatchNorm2d(300)),\n",
    "    ('ReLU2',nn.ReLU()),\n",
    "    ('Flatten',nn.Flatten()),\n",
    "    ('Linear1',nn.Linear(300,128)),\n",
    "    ('ReLU3',nn.ReLU()),\n",
    "    ('Linear2',nn.Linear(128,6)),\n",
    "]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "076b0add-7c41-43eb-84ad-a7994f5d4d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(model,input_size=(1,3,48,48))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e06252e0-1d80-44ab-a455-867118b637fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience=5, delta=0, restore_best_weights=True, path='checkpoint.pt', verbose=False):\n",
    "        self.patience = patience\n",
    "        self.delta = delta\n",
    "        self.verbose = verbose\n",
    "        self.restore_best_weights = restore_best_weights\n",
    "        self.best_loss = None\n",
    "        self.counter = 0\n",
    "        self.path = path\n",
    "        self.early_stop = False\n",
    "\n",
    "    def __call__(self, val_loss, model):\n",
    "        loss = val_loss\n",
    "\n",
    "        if self.best_loss is None:\n",
    "            self.best_loss = loss\n",
    "            torch.save(model.state_dict(), self.path)\n",
    "            # print(\"saved model1\")\n",
    "        elif loss - self.best_loss >=  self.delta:\n",
    "            self.counter += 1\n",
    "            if self.verbose:\n",
    "                print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_loss = loss\n",
    "            if self.restore_best_weights:\n",
    "                torch.save(model.state_dict(), self.path)\n",
    "            \n",
    "            self.counter = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7198e52f-5aee-4a15-a924-2582792bd01f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Create optimizer\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), # optimize newly created model's parameters\n",
    "                            lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e723edb-fe98-40ee-bf67-6a7a12f135b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
